\documentclass[a4paper, 11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}


\usepackage{mathtools, amssymb}

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{Def}{Definizione}[section]
\newtheorem*{Oss}{Osservazione}
\theoremstyle{plain}
\newtheorem{Lemma}[Def]{Lemma}
\newtheorem{Prop}[Def]{Proposizione}
\newtheorem{Teo}[Def]{Teorema}
\newtheorem{Cor}[Def]{Corollario}

\usepackage[shortlabels]{enumitem}
\setlist[enumerate, 1]{label = (\roman*)}


\DeclarePairedDelimiter{\ang}{\langle}{\rangle}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\zero}{\mathbf{0}}
\newcommand{\eset}{\varnothing}
\newcommand{\restr}[2]{{#1}_{|_{#2}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\deff}{\coloneqq}
\newcommand{\CC}{\mathcal{C}}
\DeclareMathOperator{\Mult}{Mult}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Tan}{Tan}
\DeclareMathOperator{\Gr}{Gr}
\DeclareMathOperator{\Seg}{Seg}
\DeclareMathOperator{\rk}{rk}
\DeclareMathOperator{\brk}{brk}
\DeclareMathOperator{\mrk}{mrk}
\DeclareMathOperator{\minrkop}{minrk}
\newcommand{\minrk}[4]{\minrkop(#1 \!\!\!\mod #2\ #3\ #4)}

\usepackage{booktabs}

\usepackage[autostyle, italian=guillemets]{csquotes}
\usepackage[backend=biber, style=numeric, hyperref, giveninits=true]{biblatex}
	\addbibresource{TensorSpaces.bib}
	\DeclareFieldFormat{url}{\url{#1}}

\usepackage{hyperref}
\hypersetup{hidelinks}

\title{Introduction to Tensor Spaces\\ Appunti del Corso}
\author{Mirko Torresani}
\begin{document}
	\maketitle
\section{Fatti Introduttivi}
Per noi gli spazi vettoriali saranno di dimensione finita, con campo base $\C$. 
\begin{Def}
	Il prodotto tensoriale $V_1 \otimes \dots \otimes V_n$ è definito come lo spazio $\Mult(V_1, \dots, V_n;\C)$.
\end{Def}

\begin{Def}
	Dato un tensore $f \in V \otimes W$, il suo rango $\rk f$ è 
	\[
		\rk f = \min\{s \mid f = \sum_{i = 1}^s v_i \otimes w_i\}\,.
	\]
\end{Def}
\begin{Prop}
	Il rango $\rk f$ è equivalentemente definibile come
	\begin{enumerate}
		\item il rango del morfismo $V^* \to V$ associato a $f$;
		\item posto $f = \sum c_{ij} v_i \otimes w_j$, con $(v_i)_i$ e $(w_j)_j$ rispettive basi, il rango di $f$ è il rango della matrice $(c_{ij})_{i,j}$.
	\end{enumerate}
\end{Prop}

Nel caso in cui abbiamo un prodotto tensore di più spazi, le cose si complicano.
\begin{Def}
	Dato un elemento $f \in V_1\otimes \dots\otimes V_d$, il rango $\rk f$ è definito come
	\[
		\rk f = \min\{s \mid f = \sum_{j = 1}^s v_{j,1} \otimes \dots \otimes  v_{j,d}\}
	\]
\end{Def}

Un argomento, storicamente molto importate, riguarda il \emph{calcolo del rango tensoriale}. Per una sua prima trattazione introduciamo la seguente notazione: se $f$ è un vettore in $V_1 \otimes \dots \otimes V_d$, allora $f$ induce mappe 
\[
	f_k \colon V_k^\ast \to \bigotimes_{i \neq k} V_i \quad f_k^\dagger \colon \bigotimes_{i \neq k} V_i^* \to V_k
\]
per ogni $k$.
\begin{Def}
	Un tensore $f \in V_1 \otimes \dots \otimes V_d$ si dice $V_i$-conciso, o $i$-conciso, se $f_i$.
\end{Def}
\begin{Def}
	Il multi-rango di $f$ è definito come
	\[
		\mrk f = (\rk f_1, \dots, \rk f_d) \eqqcolon (r_1, \dots, r_d) \,,
	\]
	dove $\rk f_k$ è il rango di $f_k$ come mappa lineare (o equivalentemente il rango della mappa trasporta $f_k^\dagger$).
\end{Def}

Per il resto della trattazione useremo la \emph{notazione di Einstein: quando lo stesso indice compare come pedice e apice, allora viene intesa una sommatoria rispetto a quell'indice, se non diversamente indicato}.
\begin{Prop}
	Sia $f$ un tensore, allora 
	\[
		\max_i r_i \le \rk f \le \min_i \prod_{j \neq i} r_j
	\]
\end{Prop}
\begin{proof}
	Sia $r$ il rango di $f$, e poniamo 
	\[
		f = \sum_{i=1}^r v_{1,i}\otimes\dots\otimes v_{d,i}\,.
	\]
	L'immagine della funzione trasporta $f_k^\dagger$, da $\bigotimes_{i \neq k}V_i^\ast \to V_k$, è contenuta nel generato $\ang{v_{k,1}, \dots, v_{k,r}}$, e quindi l'immagine ha dimensione ha al più dimensione $r$.
	
	Se $\{u_{i,1}, \dots, u_{i,r_i}\}$ è una base per l'immagine di $f_i^\dagger$, allora $f$ si può scrivere come
	\[
		f = \alpha^{j_1, \dots, j_d}\,u_{1,j_1}\otimes \dots \otimes u_{d,j_d}
	\]
	e per ogni $k$ 
	\[
		f = u_{1,j_1}\otimes \dots \otimes u_{k-1, j_{k-1}}\otimes \left[\sum_{j_k=1}^{r_k}\alpha^{j_1,\dots, j_d}u_{k,j_k}\right]\otimes u_{k+1, j_{k+1}}\otimes \dots \otimes u_{d,j_d}\,.
	\]
	Conseguentemente per ogni $k$, il rango $r$ è al più $\prod_{i \neq k}r_i$.
\end{proof}
\begin{Cor}
	Se $\rk f = 1$, allora $\rk f_k = 1$ per ogni $k$.
\end{Cor}
\begin{Cor}
	Fissato un certo $k$, se $r_j = 1$ per ogni $j \neq k$ allora $\rk f_k = \rk f = 1$.
\end{Cor}
\begin{Prop}
	Sia $f$ un tensore 1-conciso, tale che $r_1 \ge \dots \ge r_d$ e che $\rk f = r_1$. Allora $f_1(V_1^*)$ è generato precisamente da $r_1$ tensori indecomponibili in $V_2 \otimes \dots \otimes V_d$.
\end{Prop}
\begin{proof}
	Sappiamo che $f = \sum_{i =1}^{r_1}v_{1,i}\otimes\dots\otimes v_{d,i}$ via vettori arbitrari. Conseguentemente, l'immagine di
	\[
		f_1^\dagger \colon \bigotimes_{i > 1} V_i^\ast \to V_1\,
	\]
	è generata da $\{v_{1,1}, \dots, v_{1,r_1}\}$. Siccome il rango di $f_1$, e quindi quello di $f_1^\dagger$, è per ipotesi $r_1$, quei vettori devono essere necessariamente indipendenti. Inoltre, per ipotesi, il tensore $f$ è 1-conciso, e quindi $f_1$ è iniettivo. In definitiva, $\dim V_1^* = \dim V_1 = r_1$ e $\{v_{1,1}, \dots, v_{1,r_1}\}$ formano una base di $V_1$. 
	
	Consideriamo quindi la base duale $\{v_1^1, \dots, v_1^{r_1}\}$ di $V_1^*$. Per costruzione
	\[
		f(V_1^*) = \ang{f(v_1^1), \dots, f(v_1^{r_1})} = \ang{v_{2,i}\otimes\dots\otimes v_{d,i}}_{i = 1,\dots, r_1}\,. \qedhere
	\]
\end{proof}

Come non-esempio consideriamo $\C^2 \otimes \C^2 \otimes \C^2$, ed il tensore
\[
	f \deff e_0 \otimes e_0 \otimes e_1 + e_0 \otimes e_1 \otimes e_0 \otimes e_1 \otimes e_0 \otimes e_0 \,.
\]
Si può osservare che in effetti è 1-conciso, e che 
\[
	f(V_1^\ast) = \ang{e_0\otimes e_1 + e_1 \otimes e_0, e_0 \otimes e_0}\,.
\]
Tuttavia quest'ultima espressione non può essere ricondotta ad uno span di tensori indecomponibili. Inoltre, $\mrk f$ è $(2,2,2)$. Conseguentemente, $\rk f = 3$ come ci si può immaginare.

\begin{Prop}
	Sia $f \in V_1 \otimes\dots\otimes 	V_d$. Il rango di $f$ coincide col minimo numero di elementi indecomponibili necessari per generare uno spazio che contiene $f_1(V_1^\ast)$.
\end{Prop}
\begin{proof}
	Se $r$ è il rango di $f$, allora $f$ si scrive come $\sum_{i = 1}^r v_{1,i}\otimes \dots \otimes v_{d,i}$ e conseguentemente $f_1(V_1^\ast)$ è contenuto in $\ang{v_{2,i}\otimes\dots\otimes v_{d,i}}_{i=1}^r$.
	
	D'altra parte, supponiamo che $f_1(V_1^*)$ sia contenuto in $\ang{v_{2,i}\otimes\dots\otimes v_{d,i}}_{i=1}^r$. Fissiamo una base $\{v_{1,1}, \dots, v_{1,m}\}$ di $V_1$, ed una conseguente base duale. Allora
	\[
		f_1(v_1^k) = \alpha^{k,i}\,v_{2,i}\otimes\dots\otimes v_{d,i}\quad 1\le k\le r,
	\]
	e 
	\[
		f = \alpha^{k,i}\,v_{1,k}\otimes v_{2,i}\otimes\dots\otimes v_{d,i}\,.\qedhere
	\]
\end{proof}

Consideriamo ora il caso in cui tensoriamo solo per \emph{tre} spazi.
\begin{Def}
	Siano $A$, $B$ e $C$ tre spazi vettoriali su $\C$. Inoltre sia $\{a_1, \dots, a_n\}$ una base di $A$, e sia $V$ un sottospazio di $B \otimes C$ con base $\{v_1, \dots, v_m\}$. Una \emph{modificazione} di $f \in A \otimes B \otimes C$ è una somma della forma
	\[
		f + \sum_{i,j} a_i \otimes v_j\,.
	\]
	Analogo per $V$ in $A \otimes B$ o in $A \otimes C$.
\end{Def}
\begin{Def}
	Dato $V_1 \subseteq B \otimes C$, $V_2 \subseteq A \otimes C$ e $V_3 \subseteq A \otimes B$ il \emph{rango minimale modulo tre sottospazi $V_1$, $V_2$ e $V_3$} è 
	\[
		\minrk{f}{V_1}{V_2}{V_3} \deff \min \{\rk \tilde{f} \mid \tilde{f} \text{ modificazione ottenuta da un singolo } V_i\}\,.
	\]
\end{Def}
\begin{Prop}
	Sia $f \in A \otimes B \otimes C$ un tensore conciso di rango $r$, e poniamo $f = \sum_{k=1}^m g_k \otimes c_k$ con $g_i \in A \otimes B$ e $\{c_1, \dots, c_{m}\}$ una base di $C$. Se $g_1 \neq 0$, esistono constanti $\lambda_2, \dots, \lambda_m \in \C$ tali che 
	\[
		\hat{f} = \sum_{j=2}^{m}(g_j - \lambda_j g_1) \otimes  c_j \in A \otimes B \otimes (c_1^\bot)^*
	\]
	ha rango al più $r-1$. Se $\rk g_1 = 1$, allora $\hat{f}$ ha rango almeno $r-1$ qualunque siano le costanti.
\end{Prop}
\begin{proof}
	Sappiamo che esistono $h_1, \dots, h_r$, tensori di rango 1 in $A \otimes B$, che generano uno spazio contenente $f_3(C^*)$. Quindi
	\[
		g_j = \alpha^{j,t}\,h_t \in A \otimes B.
	\]
	
	Conseguentemente
	\[
		f = \alpha^{j,t}\, h_t \otimes  c_j\,.
	\]
	Possiamo assumere, senza perdita di generalità, $\alpha^{1,1} \neq 0$, e porre $\lambda_j \deff \alpha^{j,1}/\alpha^{1,1}$. Otteniamo quindi
	\[
		\begin{split}
			\hat{f} &= \sum_{j=2}^m(g_j - \lambda_jg_1)\otimes c_j\\
			&= \sum_{j=2}^m \left[\alpha^{j,t}h_t - \frac{\alpha^{j,1}}{\alpha^{1,1}}\,\alpha^{1,t}h_t \right]\otimes c_j\\
			&= \sum_{j=2}^m  \left[\sum_{t=2}^r\left( \alpha^{j,t} - \frac{\alpha^{j,1}\alpha^{1,t}}{\alpha^{1,1}}\right)h_t  \right] \otimes c_j
		\end{split}\,.
	\]
	Ergo $\hat{f}_3(c_1^\bot)$ è contenuto in $\ang{h_2, \dots, h_r}$, che uno span di tensori di rango 1. Quindi $\hat{f}$ ha rango al più $r-1$.
	
	Se il rango di $g_1 \in A \otimes B$ è 1, allora possiamo tranquillamente porre $h_1 = g_1$. In questo caso $\alpha^{1,t}= 0$ per ogni $t > 1$ e $\hat{f}$ assume la forma seguente, \emph{indipendentemente dalle costanti $\lambda_j \in \C$}:
	\[
		\hat{f} = \sum_{j=2}^m \sum_{t=2}^r\alpha^{j,t}\,h_t\otimes c_j = \sum_{t = 2}^th_t \otimes \left[\sum_{j=2}^m \alpha^{j,t}\, c_j\right]\,.
	\]
	
	Ma questo implica che $\hat{f}_3(c_1^\bot) $ coincide con $\ang{h_2, \dots, h_r}$, da cui
	\[
		\rk \hat{f} \ge \rk\hat{f}_3 = r-1\,.\qedhere
	\]
\end{proof}
\begin{Cor}
	Sia $f \in A \otimes B \otimes  C$, e sia $f$ un tensore $C$-conciso. Fissato un sottospazio $W$ di $C^*$, allora
	\[
		\rk f \ge \minrk{f}{0}{0}{f_3(W)} + \dim W\,,
	\]
	e l'uguaglianza si ottiene se $f(W)$ è generato da tensori di rango 1.
\end{Cor}
\begin{proof}
	Applichiamo la proposizione precedente per un numero di volte pari a $\dim W$.
\end{proof}
\begin{Cor}
	Se $f \in A \otimes B \otimes C$ è conciso, e $U \subseteq A^*$, $V \subseteq B^*$, $W \subseteq C^*$ sono sottospazi, allora
	\[
		\rk f \ge \minrk{f}{f(U)}{f(V)}{f(W)} + \dim U + \dim V + \dim W\,,
	\]
	e se $f(U)$, $f(V)$, $f(W)$ sono generati da tensori dai rango 1, vale l'uguaglianza.
\end{Cor}

\section{Algebre Tensoriali}

Parliamo brevemente di algebre tensoriali.
\begin{Def}
	Dato un gruppo $G$, un $G$-modulo è, in questo contesto, un $\C[G]$-modulo nel senso dell'algebra commutativa.
\end{Def}
\begin{Def}
	Se $G$ agisce su un $\C$-spazio $V$ e $W$ (tramite un morfismo $G \underset{\rho}{\to} GL(V)$)
	\begin{enumerate}
		\item $G$ agisce su $V^*$ via $\rho^*(g) = [\rho(g)^{-1}]^\dagger$;
		\item $G$ agisce su $V \oplus W$ via $g \cdot (v,w) = (g\cdot v, g\cdot w)$;
		\item $G$ agisce su $V \otimes W$ via $g \cdot (v\otimes w) = (g\cdot v)\otimes (g\cdot w)$.
	\end{enumerate}
\end{Def}
\begin{Def}
	L'algebra tensoriale $(TV, \otimes)$ è definita come
	\[
		TV \deff \bigoplus_{d \ge 0} V^{\otimes d}\,.
	\]
\end{Def}

Vogliamo definire \emph{l'algebra simmetrica}. 
\begin{Def}
	I $d$-tensori simmetrici sono 
	\[
		S^d V \deff \{\alpha \in V^{\otimes d} \mid \sigma \cdot \alpha = \alpha\ \forall \sigma \in S_d \}\,,
	\]
	e l'algebra simmetrica è
	\[
		SV \deff \bigoplus_{d \ge 0} S^{d}V\,.
	\]
\end{Def}

Definiamo ora la \emph{proiezione simmetrica $\pi_S$} da $TV$ in $SV$:
\[
	\pi_S(v_1 \otimes\dots\otimes v_d) = \frac{1}{d!}\sum_{\sigma \in S_d}\sigma \cdot (v_1\otimes\dots\otimes v_d)\,.
\]
\begin{Prop}
	Lo spazio $S^dV$ è generato dall'insieme $\{v^{\otimes d} \mid v \in V\}$.
\end{Prop}
\begin{proof}
	Basta osservare che 
	\[
		\sum_{\sigma \in S_d} v_{\sigma(1)}\otimes \dots \otimes v_{\sigma(d)} = \sum_{\mathclap{\substack{I \subseteq \{1,\dots, d\}\\I \neq \eset}
		}} (-1)^{d -\abs{I}} \bigg[\sum_{i \in I}v_i\bigg]^{\otimes d}\,,
	\]
	e che per ogni $\alpha \in S^dV$ la somma precedente coincide con $d!\cdot \alpha$.
\end{proof}

L'algebra $SV$ risulta effettivamente un algebra, grazie all'introduzione del \emph{prodotto simmetrico $\odot$} su $SV$ come
\[
	\alpha \odot \beta = \pi_S(\alpha\otimes\beta)	\,.
\]

\begin{Oss}
	Se $v_1, \dots, v_n$ è una base di $V$, una base di $S^dV$ è data da
	\[
		\mathcal{B}_{S^dV} = \{v_{j_1}\odot\dots\odot v_{j_d}\}_{1\le j_1 \le \dots \le j_d\le n}
	\]
	e quindi
	\[
		\dim S^dV = \binom{n+d-1}{d}\,.
	\]
\end{Oss}

In seguito sarà molto importante parlare di \emph{decomposizione di tensori}. Un esempio in quella direzione viene ai prossimi risultati.
\begin{Prop}
	Dato un tensore $f \in S^2V$ di rango $r$, esso ammette una decomposizione della forma
	\[
		f = \sum_{i=1}^r v_i \otimes v_i\,.
	\]
\end{Prop}
\begin{Prop}
	La rappresentazione di $GL(V)$ sullo spazio vettoriale $S^2V$ è irriducibile.
	\begin{proof}
		Sia $W \subseteq S^2V$ un $GL(V)$-sottomodulo contenente un tensore $f$ non nullo. Sicuramente possiamo scrivere
		\[
			f = \sum_{i=1}^rv_i \otimes v_i \quad v_i \in V, \lambda_i \in \C\,.
		\]
		con $v_1,\dots, v_r$ indipendenti.
		
		Sia un morfismo $g \in GL(V)$ per cui $g(v_1) = 2v_1$ e $g(v_i) = v_i$ per ogni $i > 1$. Allora vale che 
		\[
			W \ni \frac{1}{3}(g \cdot f - f) = v_1\otimes v_1\,,
		\]
		e quindi 
		\[
			S^2V = \ang{(g\cdot v_1) \otimes (g\cdot v_1)}_{g \in GL(V)} \subseteq W\qedhere
		\]
	\end{proof}
\end{Prop}

Possiamo analogamente definire un \emph{rango simmetrico}.
\begin{Def}
	Il rango simmetrico di $f \in S^dV$ è
	\[
		\rk_S f \deff \min\{r \in \N \mid f = v_1^{\otimes d} + \dots + v_r^{\otimes d}\}\,.
	\]
\end{Def}
Sicuramente $\rk f \le \rk_S f$, e vale l'uguaglianza per $d = 2$. È una congettura se sono uguali, detta \emph{congettura di Comon}. Nel 2018 Shitov \cite{Shitov2018} ha pensato di trovare un controesempio, smentito da sé stesso nel 2024 \cite{Draisma2024}.

\begin{Prop}
	
	Posto $\C[V]$ l'algebra delle funzioni $V \to \C$ generata da $V^*$, lo spazio $S^dV^*$ è isomorfo a $\C[V]_d \simeq \C[x_1, \dots, x_n]_d$.
\end{Prop}
\begin{proof}
	La mappa che funziona è 
	\[
		\Phi \colon S^dV^* \to \C[V]_d\,, \ \phi \mapsto f_\phi\,,
	\]
	con
	\[
			f_\phi(v) = \phi(v,\dots, v)\,. \qedhere
	\]
\end{proof}
\begin{Def}[Waring rank]
	Per ogni $f \in \C[x_1, \dots, x_n]_d$ il rango di Waring è 
	\[
		\rk_S f = \min\{r \in \N \mid f = l_1^d + \dots + l_r^d, \ l_i \text{ forma lineare}\}\,.
	\]
\end{Def}

\begin{Def}
	I $d$-tensori antisimmetrici sono 
	\[
	\Lambda^d V \deff \{\alpha \in V^{\otimes d} \mid \sigma \cdot \alpha =\sgn(\sigma)\, \alpha\ \forall \sigma \in S_d \}\,,
	\]
	e l'algebra antisimmetrica è
	\[
	\Lambda V \deff \bigoplus_{d \ge 0} \Lambda^{d}V\,.
	\]
\end{Def}

Definiamo la proiezione antisimmetrica $\pi_\Lambda$ come
\[
	\pi_\Lambda(v_1 \otimes\dots\otimes v_d) = \frac{1}{d!}\sum_{\sigma \in S_d}\sgn(\sigma)\,v_{\sigma(1)}\otimes\dots\otimes v_{\sigma(d)}\,.
\]
Analogamente a quanto fatto prima definiamo il prodotto antisimmetrico (o \emph{wedge}) come
\[
	\alpha \wedge \beta \deff \pi_\Lambda(\alpha\otimes\beta)\,.
\]
\begin{Prop}
	Un insieme finito $v_1, \dots, v_d$ è linearmente indipendente se e solo se 
	\[
		v_1\wedge \dots \wedge v_d = 0\,.
	\]
\end{Prop}
\begin{Cor}
	Una base $\mathcal{B}_{\Lambda^dV}$ di $\Lambda^dV$ è 
	\[
		\mathcal{B}_{\Lambda^dV} = \{v_{j_1}\wedge\dots\wedge v_{j_d}\}_{1\le j_1 < \dots< j_d\le n}
	\]
	e quindi
	\[
		\dim \Lambda^dV = \binom{n}{d}\,.
	\]
\end{Cor}
\begin{Prop}
	Lo spazio $\Lambda^2V$ è un $GL(V)$-modulo irriducibile.
\end{Prop}

\section{Decomposizione di Tensori}

Dati due spazi $A$, $B$, lo spazio $G \deff GL(A) \times (B)$ è incluso in $GL(A\otimes B)$. Dei teoremi di semplice decomposizione sono dati dai seguenti.
\begin{Prop}
	Lo spazio $S^2(A\otimes B)$ si $G$-decompone come
	\[
		S^2(A \otimes B) = (S^2A \otimes S^2B) \oplus (\Lambda^2A \otimes \Lambda^2B)\,.
	\]
	Ed allo stesso modo $\Lambda^2(A\otimes B)$ si $G$-decompone come
	\[
		\Lambda^2(A\otimes B) = (S^2A \otimes \Lambda^2B) \oplus (S^2A \otimes \Lambda^2B)\,.
	\]
\end{Prop} 

Gli elementi di $(\C^2)^{\otimes 3}$ hanno le orbite secondo $(GL_2(\C))^3$ che seguono la seguente tabella:
\[
\begin{array}{cccccc}
	\toprule
	\text{orbita} & r_1 & r_2 & r_3 &  \rk f & \text{rappresentante}\\
	\midrule
	A & 1 & 1 & 1 & 1 & a_0\otimes b_0 \otimes c_0 \\
	B_1 & 1 & 2 & 2 & 2 & a_0\otimes b_0 \otimes c_0 + a_0\otimes b_1 \otimes c_1\\
	B_2 & 2 & 1 & 2 & 2 & a_0\otimes b_0 \otimes c_0 + a_1\otimes b_0 \otimes c_1\\
	B_3 & 2 & 2 & 1 & 2 & a_0\otimes b_0 \otimes c_0 + a_1\otimes b_1 \otimes c_0\\
	W & 2 & 2 & 2 & 3 & a_0\otimes b_1 \otimes c_1 + a_1\otimes b_0 \otimes c_1 + a_1\otimes b_1 \otimes c_0\\
	G & 2 & 2 & 2 & 2 & a_0\otimes b_0 \otimes c_0 + a_1\otimes b_1 \otimes c_1 \\
	\bottomrule
\end{array}
\]
\section{Varietà Algebriche Tensoriali}
\begin{Def}
	Sia $Z \subseteq \PP V$ un sottoinsieme dello spazio proiettivo su $V$. Il \emph{cono affine} è $\hat{V} \deff \pi^{-1}(Z)$, con $\pi$ la proiezione proiettiva.
\end{Def}
\begin{Def}
	Se $X$ l'insieme di zeri comuni di $S \subseteq S^\bullet V^\ast$, allora poniamo $X \deff Z(S)$.
\end{Def}

\begin{Def}
	Viceversa, dato $A \subseteq \PP V$, 
	\[
		I(A) \deff \{F \in S^\bullet V^\ast \mid F(a) = 0\ \forall a \in \hat{A}\}
	\]
	è \emph{l'ideale di $A$}.
\end{Def}
\begin{Def}
	L'embedding di Segre è dato da
	\[
	\begin{split}
		\Seg \colon \PP A \times \PP B &\to \PP (A \otimes B)\\
		([a], [b]) &\mapsto [a \otimes b]
	\end{split}
	\]
\end{Def}
L'immagine è data dalla proiezione delle matrici $\dim A \times \dim B$ di rango $1$, cioè dal luogo di zeri di $\Lambda^2A^\ast \otimes \Lambda^2B^\ast \subseteq S^2(A \otimes B)$.
\begin{Prop}
	In generale l'analoga mappa da $\PP A_1 \times \dots \times \PP A_n $ a $\PP(A_1 \otimes\dots\otimes A_n)$ dà come immagine un'insieme chiuso.
\end{Prop}
\begin{Def}
	La $d$-mappa di Veronese è
	\[
	\begin{split}
		v_d \colon \PP V &\to \PP(S^dV) \\
		[a] &\mapsto [a^{\otimes d}]
	\end{split}
	\]
\end{Def}

L'immagine è costituita da $\Seg((\PP V)^n) \cap \PP(S^d V)$, e quindi è una varietà proiettiva.

\begin{Def}
	Data una mappa $f$ da $V$ in sé, $f^{\wedge m}$ è la naturale endomorfismo di $\Lambda^m V$. Se $m = \dim V$, $f^{\wedge m}$ è la moltiplicazione per $\det(f)$.
\end{Def}
\begin{Def}
	La Grasmanniana è 
	\[
		\Gr(r,V) \deff \{[v_1 \wedge \dots \wedge v_r] \mid v_f \in V\} \subseteq \PP(\Lambda^r V).
	\]
\end{Def}
Osserviamo che nel proiettivo un tale prodotto wedge è insensibile a cambi di base del sottospazio generato. La Grassmaniana parametrizza quindi i sottospazi 

\begin{Def}
	Per ogni $\phi \in V^\ast$ e $v \in V$, definiamo $\phi \,\lrcorner \,v \deff \phi(v)$. Per induzione se $\phi \in V^\ast$, $v \in V$ e $f \in \Lambda^k V$ imponiamo
	\[
		\phi\,\lrcorner\,(v \wedge f) \deff (\phi \,\lrcorner\, v) \wedge f - v \wedge (\phi \,\lrcorner\, f)\,.
	\]
	Infine imponiamo $(\phi \wedge g)\,\lrcorner\, f \deff \phi\,\lrcorner\,(g\, \lrcorner\, f)$.
\end{Def}
\begin{Prop}
	$f \in \Lambda^r V$ può essere scritta come un prodotto wedge $w_1 \wedge\dots\wedge w_r$ se e solo se 
	\[
		(\psi \,\lrcorner\,f) \wedge f = 0\ \forall \psi \in \Lambda^{r-1}V^*
	\]
\end{Prop}
In particolare, se 
\[
	f = p_{i_1\dots i_r}v^{i_1} \wedge \dots \wedge v^{i_r}
\] 
allora l'equazione diventa
\[
	\sum_{k=1}^{r+1}(-1)^kp_{i_1\dots i_{r-1}j_k}\,p_{j_1\dots j_{k-1}j_{k+1}\dots j_{r+1}} = 0\,,
\]
per ogni scelta di multiindici $(i_1, \dots, i_k)$ e $(j_1, \dots, j_k)$. Avendo ottenuto una equazione polinomiale, $\Gr(r,V)$ è una varietà proiettiva.

Parliamo ora di spazi tangenti. 
\begin{Def}
	Sia $M \subseteq V$ un sottoinsieme e $v \in V$. Allora
	\[
		\hat{T}_vM \deff \Big\{\frac{d\gamma}{dt}\Big|_{t = 0} \mid \gamma \colon \C \to M \text{ curva liscia}\Big\}
	\]
	è lo spazio tangente.
\end{Def}
Osserviamo che lo spazio tangente su $v$ o su $\lambda v$ rimane invariato per $\lambda \in \C^*$.

\begin{Def}
	Sia $X \subseteq \PP V$ una varietà proiettiva. Un punto $v \in X$ si dice liscio se esiste un insieme aperto $U$ (di Zarinksi) su cui lo spazio tangente $\hat{T}_w X$ ha la stessa dimensione per ogni $w \in U$. L'insieme dei punti singolari è un chiuso proiettivo.
\end{Def}

Poniamo quindi 
\[
	\dim X \deff \dim (\hat{T}_v X)-1
\]
con $v$ un punto liscio.

\begin{Prop}
	Vale che
	\[
		\hat{T}_{v_1\otimes \dots \otimes v_d} \Seg(\PP V_1 \times \dots \times \PP V_d) = \sum_{j =1}^d
 v_1 \otimes \dots \otimes v_{j-1}\otimes V_j\otimes v_{j+1} \otimes \dots \otimes v_d\,.
 	\]
\end{Prop}
\begin{Prop}
	Analogamente vale che
	\[
		\hat{T}_{[v^{\otimes d}]} v_d(\PP V) = \{[v^{\otimes\, (d-1)}\otimes w] \mid w \in V\}\,.
	\]
\end{Prop}

Parliamo ora di orbite. Sulle nostre varietà proiettive facciamo agire $G \deff SL(V)$. È il rivestimento universale (di grado finito) di $PGL(V)$. 
\begin{Prop}[Borel]
	Se un'azione è algebrica, allora per ogni orbita $\mathcal{O}$ la sua chiusura è ancora $G$-invaiante e 
	\[
		\overline{\mathcal{O}} = \mathcal{O} \cup \{\text{orbite di dimensione minore}\}.
	\]
\end{Prop}
Conseguentemente, le orbite di dimensione minore sono chiuse, e se l'azione è irriducibile, essa è unica.

In questa ottica delle azioni, guardiamo alle tre varietà di prima.
\begin{enumerate}
	\item Dato l'embedding di Veronese $v_d$, esso è $G$-equivariante, e la sua immagine è \emph{l'orbita chiusa} per l'azione di $G$ su $\PP(S^dV)$. 
	
	\item Per quanto riguarda, l'embedding di Segre, l'immagine è l'orbita chiusa per l'azione di $SL(V_1) \times \dots\times SL(V_d)$.
	
	\item Possiamo anche considerare varietà di Segre-Veronese denntro 
	\[
		\PP(S^{a_1}V \otimes \dots \otimes S^{a_d}V)
	\]
	\item Le varietà di Grassmann \emph{proiettive}, indicate come $\Gr(\PP^k, \PP V)$, possiedono delle naturali coordinate di Plücker che le immergono dentro $\PP(\Lambda^{k+1} V)$.
\end{enumerate}

Parliamo ora di \emph{varietà secanti}. Iniziamo ora con delle definizioni.
\begin{Def}
	Siano $X$ e $Y$ sottoinsiemi di $\PP(W)$. Il Join è definito come
	\[
		J(X,Y) \deff \overline{\bigcup_{\substack{x \in X \\ y \in Y}} \ang{x,y}}
	\]
\end{Def}
La chiusura serve per prendere anche le tangenti come limite di secanti.


Se $X = Y = v_3(\PP\C^2)$, dato in coordinate come ($\dim_\C S^3\C^2 = 4$)
\[
	[x_0, x_1] \mapsto [x_0^3, 3x_0^2x_1, 3x_0x_1^2, x_1^3]\,,
\]
allora $X$ prende il nome di \emph{cubica gobba}. Studiamo ora l'azione di $SL_2$ su $\PP(S^3\C^2)$. Abbiamo tre orbite che sono 
\[
	X,\ \Tan(X) \setminus X,\ \PP(S^3\C^2) \setminus \Tan(X)
\]

Se $f \in S^3\C^2$, allora può essere pensato come un polinomio omogeneo cubico in $x_0$ e $x_1$. Su $\C$ ricade in tre casistiche
\begin{enumerate}
	\item $f$ una radice tripla, e appartiene a $X$.
	\item $f$ ha una radice singola ed una doppia, ed appartiene a $\Tan(X) \setminus X$;
	\item $f$ ha tre radici singole, ed appartiene a $\PP(S^3\C^2) \setminus \Tan(X)$.
\end{enumerate}

Può essere dimostrato che $X \cup (\PP(S^2\C^3)\setminus \Tan(X))$ coincide esattamente con l'unione delle secanti. Detto altrimenti, $J(X,X)$ è tutto lo spazio $\PP(S^3\C^2)$.

\begin{Def}
	La varietà secante è data da 
	\[
		\sigma_k(X) \deff J(X, \dots, X)\,.
	\]
\end{Def}
Abbiamo quindi una catena ascendente
\[
	X \subseteq \sigma_1(X) \subseteq \dots \subseteq \sigma_{p_0}(X) = \PP(W)\,.
\]

Se consideriamo $X$ come $\PP(V_1) \times \PP(V_2)$ dentro $\PP(V_1 \otimes V_2)$, allora
\[
	\sigma_r(X) = \{f \in \Hom(V_1^{\vee}, V_2) \mid \rk f \le r\}\,,
\]
in quanto ogni matrice di rango $r$ (in senso matriciale) può essere scritta come somma di matrici di rango 1.

Si può dimostrare che la chiusura di Zarinksky di 
\[
	\{f \in \Hom(V_1^\vee, V2) \mid \rk f = r\}
\]
coincide precisamente con $\sigma_r(X)$. Questo recupera il risultato di Borel.

Consideriamo ora il caso $X = v_d(\PP^1\C)$, con $d \ge 3$.

Per $d = 3$ siamo di fronte alla cubica gobba. Se supponiamo di proiettare questa cubica su un piano, usando un generico punto $p \notin X$ come fuoco, osserviamo che la proiezione ha un nodo precisamente se $p$ è in una secante, o ha una cuspide precisamente quando $p$ sta in una tangente. Ma una cubica in un piano può solo avere un nodo. Quindi se $p$ sta su una secante, essa è unica. Analogamente se $p \notin X$ sta su una tangente essa è unica. Si può provare, come già detto, che $\sigma_2(X) = \PP^3\C$\,.

Per $d = 4$ stiamo guardando l'immersione di $\PP^1\C$ in $\PP^4\C$. In questo caso abbiamo infinite $SL_2$-orbite, in quanto quattro radici non possono essere generalmente portate una dentro l'altra. La catena secante è della forma
\[
	X = \sigma_1(X) \subseteq \sigma_2(X) \subseteq \sigma_3(X) = \PP^4
\]
Capiamo l'equazione di $\sigma_2(X)$. Sia
\[
	S^2\C^{2\vee} = \{\alpha_0\partial_0^2 + 2 \alpha_1\partial_0\partial_1 + \alpha_2\partial_1^2\}
\]
e consideriamo la mappa
\[
\begin{split}
	\CC_f \colon S^2\C^{2\vee} &\to S^2\C^2 \\
	\partial &\mapsto \partial f
\end{split}
\]	
con $f \in S^4\C^2$.

Sia $\ell$ una forma lineare. Allora l'immagine di $\CC_{\ell^4}$ è $\C$-generata da $\ell^2$ ed ha dimensione 1. Inoltre,
\[
	\CC_{\lambda f + \mu g} = \lambda \CC_f + \mu \CC_g
\]
e quindi se $\ell_1$, $\ell_2$ sono due forme lineari, allora
\[
	\rk \CC_{\lambda_1 \ell_1^4 + \lambda_2 \ell_2^4} \le 2\,.
\]
Quindi la mappa precedente ha sempre determinante nullo, in quando $\dim S^2\C^2 = 3$.

Conseguentemente, la varietà $\sigma_2(X)$ è contenuta in $V(\det \CC_f)$. Inoltre vale l'uguaglianza in quanto $\det \CC_f$ è un polinomio cubico irriducibile.

Inoltre, $SL_2$ agisce su $S^4\C^2$, e quindi su 
\[
	\bigoplus_d S^d(S^4\C^2)\,.
\]
\begin{Prop}
	Il sottoanello
	\[
		\left[\bigoplus_d S^d(S^4\C^2)\right]^{SL_2} \subseteq \bigoplus_d S^d(S^4\C^2)
	\]
	è un anello polinomiale completo: $\C[I,J]$, con $\deg I = 2$ e $\deg J = 3$. Questo fatto (mi fido) è molto raro in teoria degli invarianti. Inoltre come varietà algebrica è $\PP^1\C$, oltre ad essere liscia. A meno di multipli scalari $J = \det \CC_f$. 
\end{Prop}

\begin{Lemma}
	$\dim \sigma_r(X) \le r\,\dim(X) + (r-1)$
\end{Lemma}
\begin{proof}
	Consideriamo 
	\[
		\sigma^r(X) \deff \{(x_1, \dots, x_r, y) \mid y \in \ang{x_1, \dots, x_r}\}
	\]
	dentro 
	\[
		X \times\dots\times X\times \PP W
	\]
	E consideriamo le due mappe
	\[
		X \times\dots\times X \overset{\pi_1}{\longleftarrow} \sigma^r(X) \overset{\pi_2}{\longrightarrow} \PP W \,.
	\]
	
	Notiamo che $\pi_2(\sigma^r(X)) = \sigma_r(X)$, e che $\pi_1$ è suriettiva con fibra generica $\PP^{r-1}\C$. Conseguentemente
	\[
	\begin{split}
			\dim \sigma_r(X) \le \dim \sigma^r(X) &= \dim(\text{Fibra}) + \dim(X \times\dots\times X) \\
			&= (r-1) + r\dim(X)\,. \qedhere
	\end{split}
	\]
\end{proof}
Si postula che valga l'uguaglianza.

\begin{Def}
	$X$ si dice essere $(h+1)$-difettivo se $\sigma_{h+1} X $ ha dimensione minore del minimo tra $X$ e la stima del teorema precedente.
\end{Def}
\begin{Lemma}[Terracini]
	Se $x_i \in X_i$ sono punti generici, e $p \in \ang{x_1, \dots, x_{h+1}}$ è generico, allora
	\[
		T_pJ(X_1, \dots, X_{h+1}) = \ang{T_{x_1}X_1, \dots, T_{x_{h+1}}X_{h+1}}\,.
	\]
\end{Lemma}

Sia ora $X \subseteq \PP^N$, e $p \in \PP^N$
\begin{Def}
	Il rango $\rk_X(p)$ è definito come
	\[
		\rk_X(p) = \min\{h+1 \mid p \in \ang{x_1, \dots, x_{h+1}}\}\,.
	\]
\end{Def}
\begin{Def}
Il rango di bordo $\brk_X(p)$ è definito come
\[
\brk_X(p) = \min\{h+1 \mid p \in \sigma_{h+1}(X)\}\,.
\]
\end{Def}
Ovviamente $\brk_X(p)$ è minore di $\rk_X(p)$.

Se $X = v_d(\PP V) = \{\ell^{\otimes d} \mid \ell \in \PP V\}$ in $\PP(S^d V)$, allora stiamo sostanzialmente guardando al rango simmetrico.

Se $X' = \PP V \times \dots \times \PP V$ dentro $\PP(V^{\otimes d})$, stiamo guardando al rango normale.

Siccome $v_d(\PP V)$ coincide con $X' \cap \PP(S^d V)$, allora ogni elemento di $\PP(S^dV)$ ha due ranghi. È una congettura se sono uguali.

Inoltre,  sicuramente vero che
\[
	\sigma_{h+1}(v_d(\PP V)) \subseteq \PP(S^d V) \cap \sigma_{h+1}(X')\,.
\]
È una congettura se valga l'uguaglianza.\vspace{0.5cm}

\noindent\fbox{\parbox{\textwidth}{Note terminate a causa della presenza di appunti del Prof.\ Ottaviani sulla teoria dell'apolarità}}

\printbibliography
\end{document}